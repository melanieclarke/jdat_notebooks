{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a779cd03-c144-4a9f-90e1-38bc98695a95",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# NIRSpec IFU Pipeline Processing ERO 02732 NGC 7319 AGN -- Point Source\n",
    "<hr style=\"border:3px solid black\">\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* [1. Introduction](#intro)\n",
    "* [2. Import Library](#imports)\n",
    "* [3. Convenience Functions](#func)\n",
    "* [4. Directory Set-Up](#dir_setup)\n",
    "* [5. Download the data](#data)\n",
    "* [6. Stage 1](#stage1)\n",
    "* [7. Stage 2](#stage2)\n",
    "* [8. Stage 3](#stage3)\n",
    "    * [8.1 New Outlier Detection Algorithm](#outlier_detection_new)\n",
    "    * [8.2 Extract 1-D Step: Modified Reference File](#extract_1d)\n",
    "* [About This Notebook](#about)\n",
    "\n",
    "\n",
    "\n",
    "## 1. Introduction <a id='intro'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "End-to-end calibration of JWST data is divided into 3 main stages of processing. This notebook explores how to run the JWST calibration pipeline stages 1-3 for NIRSpec IFU spectroscopic data.\n",
    "   <figure>\n",
    "       <img src='./NGC_7319_AGN.png' title=\"Figure 1: NGC 7319 AGN\" alt=\"NGC_7319_AGN\" class=\"bg-primary\" align=\"right\" style=\"width: 400px; height: 350px;\"/>\n",
    "   </figure>\n",
    "\n",
    ">* **`STAGE 1`** ([calwebb_detector1](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html#calwebb-detector1)): consists of detector-level corrections, performed on a group-by-group basis, followed by ramp fitting.\n",
    "    * **Input**: Raw exposure (`uncal.fits`) containing original data from all detector readouts (ncols x nrows x ngroups x nintegrations).\n",
    "    * **Output**: Corrected countrate (slope) image (`rate.fits`) \n",
    ">* **`STAGE 2`** ([calwebb_spec2](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_spec2.html#calwebb-spec2)): consists of additional instrument-level and observing mode corrections and calibrations.\n",
    "    * **Input**: A single corrected countrate (slope) image (`rate.fits`) or an ASN file listing multiple inputs.\n",
    "    * **Output**: A fully calibrated unrectified exposure (`cal.fits`). For NIRSpec IFU data, the `cube_build` step returns a 3-D IFU spectroscopic cube (`s3d.fits`). The `extract_1d` step  returns 1-D extracted spectral data products (`x1d.fits`)\n",
    ">* **`STAGE 3`** ([calwebb_spec3](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_spec3.html#calwebb-spec3)): consists of additional corrections (e.g. `outlier_detection`) and routines for combining calibrated data from multiple exposures (e.g. dither/nod pattern) into a single combined 2-D or 3-D spectral product and a combined 1-D spectrum. \n",
    "    * **Input**: An ASN file that lists multiple calibrated exposures (`cal.fits`).\n",
    "    * **Output**: For NIRSpec IFU data, a resampled and combined 3-D IFU cube (`s3d.fits`) and a 1-D extracted spectrum (`x1d.fits`)\n",
    "\n",
    "Here, we will focus on the mechanics of processing \"real\" example data [(NGC 7319 AGN)](#NGC_7319_AGN) from Early Release Science (ERS) Proposal ID 2732, including how to use associations for multi-exposure combination, how to interact and work with data models for each product, and in this particular case, how to manually process the compact region at the center of the AGN as a point source.\n",
    "\n",
    "Most processing runs shown here use the default reference files from the Calibration Reference Data System (CRDS), with one exception at the end to show an example of how to modify/override. Please note that pipeline software development is a continuous process, so results in some cases may be slightly different if using a subsequent version. There are also a few known issues with some of the pipeline steps in this build that we expect to be fixed in the near future. Until then, at various steps, we provide users with the current processing recommendations when running the pipeline manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917a0a3d-aca9-4481-85b2-00f5b1136951",
   "metadata": {},
   "source": [
    "## 2. Import Library <a id='imports'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230afa9-1909-4b20-a46c-38e9832df227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------JWST Calibration Pipeline Imports-------------------------------------------\n",
    "\n",
    "import jwst\n",
    "import crds\n",
    "from jwst import datamodels\n",
    "from jwst.pipeline import Detector1Pipeline   # calwebb_detector1\n",
    "from jwst.pipeline import Spec2Pipeline       # calwebb_spec2\n",
    "from jwst.pipeline import Spec3Pipeline       # calwebb_spec3\n",
    "from jwst.extract_1d import Extract1dStep     # Extract1D Individual Step\n",
    "\n",
    "print(\"JWST Calibration Pipeline Version={}\".format(jwst.__version__))\n",
    "print(\"Current Operational CRDS Context = {}\".format(crds.get_default_context()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbdca5b-af15-424c-a1d4-525094dfe17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------File Operation Imports------------------------------------------------\n",
    "import glob\n",
    "import os\n",
    "import asdf\n",
    "import json\n",
    "from shutil import copy\n",
    "\n",
    "# --------------------------------------------Astropy/Astroquery Imports--------------------------------------------\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import ImageNormalize, ManualInterval, LogStretch, LinearStretch, AsinhStretch\n",
    "import astroquery\n",
    "from astroquery.mast import Mast\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "# ------------------------------------------------Plotting Imports--------------------------------------------------\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as grd\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib import cm\n",
    "\n",
    "# ----------------------------------------------General Imports-----------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Set to 'default' to turn warnings back on\n",
    "\n",
    "# Use this version for non-interactive plots (easier scrolling of the notebook)\n",
    "%matplotlib inline\n",
    "# Use this version (outside of Jupyter Lab) if you want interactive plots\n",
    "# %matplotlib notebook\n",
    "\n",
    "# These gymnastics are needed to make the sizes of the figures\n",
    "# be the same in both the inline and notebook versions\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches': None}\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba6c5c1-5f24-467d-9895-8d534c64ff99",
   "metadata": {},
   "source": [
    "## 3. Convenience Functions <a id='func'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f45048e-4112-4c47-91cc-bd461d778779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(data_2d, vmin, vmax, xsize=15, ysize=15, title=None, zoom_in=None, aspect=1, scale='log', units='DN/s', cmap='jet'):\n",
    "    \"\"\"\n",
    "    Function to generate a 2-D, log-scaled image of the data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_2d : numpy.ndarray\n",
    "        2-D image to be displayed\n",
    "    vmin : float\n",
    "        Minimum signal value to use for scaling\n",
    "    vmax : float\n",
    "        Maximum signal value to use for scaling\n",
    "    xsize, ysize: int\n",
    "        Figure Size\n",
    "    title : str\n",
    "        String to use for the plot title\n",
    "    zoom_in: list \n",
    "        Zoomed in Region of interest [xstart,xstop,ystart,ystop]\n",
    "    aspect: int\n",
    "        Aspect ratio of the axes\n",
    "    scale : str\n",
    "        Specify scaling of the image. Can be 'log' or 'linear' or 'Asinh'\n",
    "    units : str\n",
    "        Units of the data. Used for the annotation in the color bar. Defualt is DN/s for countrate images\n",
    "    cmap: str\n",
    "        Color Map for plot\n",
    "    \"\"\"\n",
    "    # -----------------------------------------Scaling Information----------------------------------------\n",
    "    \n",
    "    if scale == 'log':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=LogStretch())\n",
    "    elif scale == 'linear':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=LinearStretch())\n",
    "    elif scale == 'Asinh':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=AsinhStretch())\n",
    "    \n",
    "    # --------------------------------------------Set Up Figure-------------------------------------------\n",
    "\n",
    "    fig = plt.figure(figsize=(xsize, ysize))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    im = ax.imshow(data_2d, origin='lower', norm=norm, aspect=aspect, cmap=cmap)\n",
    "\n",
    "    fig.colorbar(im, label=units)\n",
    "    plt.xlabel('Pixel column')\n",
    "    plt.ylabel('Pixel row')\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    \n",
    "    # Zoom in on a portion of the image? \n",
    "    if zoom_in:\n",
    "        # inset axis \n",
    "        axins = ax.inset_axes([0.5, 0.6, 0.5, 0.3])\n",
    "        \n",
    "        axins.imshow(data_2d, origin=\"lower\", norm=norm, aspect=aspect, cmap=cmap)\n",
    "        \n",
    "        # subregion of the original image\n",
    "        axins.set_xlim(zoom_in[0], zoom_in[1])\n",
    "        axins.set_ylim(zoom_in[2], zoom_in[3])\n",
    "        axins.set_xticklabels([])\n",
    "        axins.set_yticklabels([])\n",
    "        ax.indicate_inset_zoom(axins, color=\"black\", edgecolor=\"black\", linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b0f74-0d54-4b89-aad4-e30c02946d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ifu_cubeslices(s3d_file_list, wavelength_slices=[], spaxel_locs=[], y_scale=None, cmap='jet', vmin_vmax=[[[0, 15e1]]], save_figure=False, title=None, title_font=30):\n",
    "    \"\"\"\n",
    "    Function to that takes a 3-D IFU data cube and generates: \n",
    "    \n",
    "    > 2-D cube slices based on wavelength (microns)\n",
    "    > Associated 1-D spectrum for a designated spaxel (spatial pixel) in the data cube\n",
    "    > Corresponding 3-D weight image giving the relative weights of the output spaxels\n",
    "    \n",
    "    Note: This function can accommodate multiple detectors plotted side-by-side. \n",
    "    The general format would follow [[detector 1 info], [detector 2 info]].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s3d_file_list: list of str\n",
    "        3-D IFU data cube fits file list \n",
    "    wavelength_slices: tuple\n",
    "        List of wavelength values (microns) at which to create 2-D slices. \n",
    "    spaxel_locs: tuple\n",
    "        List of spaxel locations in which to plot the associated 1-D spectrum. (One spaxel location per slice)\n",
    "    y_scale: tuple\n",
    "        Y-axis limits for the associated 1-D spectrum of the spaxel. Default is to use the ymin and ymax of the data. \n",
    "    cmap: str\n",
    "        Color Map \n",
    "    vmin_vmax: tuple\n",
    "        Minimum & Maximum signal value to use for scaling (e.g., [[[vmin,vmax],[vmin,vmax]], [[vmin,vmax], [vmin,vmax]]])\n",
    "    title: str\n",
    "        Figure Title. Default is None. \n",
    "    title_font:int\n",
    "        Title Font Size\n",
    "    save_figure: bool\n",
    "        Save figure?         \n",
    "    \"\"\"\n",
    "    \n",
    "    # ---------------------------------------------- Set-up Figure -------------------------------------------------\n",
    "\n",
    "    # Plot Slices From the Cube\n",
    "    fig, axs = plt.subplots(3, np.array(wavelength_slices).size, figsize=(8*np.array(wavelength_slices).size, 18))\n",
    "    gs = grd.GridSpec(3, np.array(wavelength_slices).size, height_ratios=[1]*3, width_ratios=[1]*np.array(wavelength_slices).size, hspace=0.4, wspace=0.7)\n",
    "\n",
    "    total_num_plots = 3*np.array(wavelength_slices).size\n",
    "    \n",
    "    plot_count = 0\n",
    "    # ---------------------------------------------Open Files------------------------------------------------------\n",
    "    \n",
    "    for s3d_file in s3d_file_list:\n",
    "        \n",
    "        root = s3d_file[:-9] # Root file name \n",
    "\n",
    "        s3d = fits.open(s3d_file) # 3-D IFU data cube fits file \n",
    "        x1d3 = datamodels.open(root+'_x1d.fits') # 1-D Extracted Spectrum            \n",
    "    \n",
    "        # --------------------------------Wavelength & Surface Brightness/Flux Arrays------------------------------\n",
    "    \n",
    "        x1d3wave = x1d3.spec[0].spec_table.WAVELENGTH\n",
    "            \n",
    "        # --------------------------------------Data & Header Information------------------------------------------\n",
    "\n",
    "        # SCI Extension: [Type:ImageHDU  Cards:92   Dimensions:(57, 61, 973)   Format:float32]\n",
    "        cube = s3d[1].data # Science data\n",
    "        wcs = WCS(s3d[1].header) # World Coordinate System (WCS) Transformation keywords   # noqa\n",
    "        wmap = s3d[4].data # 3-D weight image giving the relative weights of the output spaxels.\n",
    "        cdelt1 = s3d[1].header['CDELT1']*3600. # Axis 1 coordinate increment at reference point  # noqa\n",
    "        cdelt2 = s3d[1].header['CDELT2']*3600. # Axis 2 coordinate increment at reference point  # noqa\n",
    "        cdelt3 = s3d[1].header['CDELT3'] # Axis 3 coordinate increment at reference point \n",
    "        crval3 = s3d[1].header['CRVAL3'] # Third axis value at the reference pixel  \n",
    "\n",
    "        # Wavelength range of the grating/filter combination\n",
    "        wavstart = s3d[1].header['WAVSTART']\n",
    "        wavend = s3d[1].header['WAVEND']\n",
    "        s3d.close()\n",
    "    \n",
    "        # ---------------------------------------------------Plots-------------------------------------------------\n",
    "        \n",
    "        cmap_custom = cm.colors.LinearSegmentedColormap.from_list(\"\", [\"darkred\", \"darkturquoise\", \"blue\"])\n",
    "        colors = cmap_custom(np.linspace(0, 1, np.array(wavelength_slices).size))\n",
    "\n",
    "        # To Account for if NRS1 & NRS2 are both being plotted Side-by-side\n",
    "        if len(wavelength_slices) != 1:\n",
    "            if 'nrs1' in s3d_file:\n",
    "                wavelengths = wavelength_slices[0]\n",
    "                spaxel_loc = spaxel_locs[0]\n",
    "                vmin_vmax_vals = vmin_vmax[0]\n",
    "                \n",
    "                if y_scale:\n",
    "                    y_scales = y_scale[0]\n",
    "\n",
    "            elif 'nrs2' in s3d_file:\n",
    "                wavelengths = wavelength_slices[1]\n",
    "                spaxel_loc = spaxel_locs[1]\n",
    "                vmin_vmax_vals = vmin_vmax[1]\n",
    "                if y_scale:\n",
    "                    y_scales = y_scale[1]\n",
    "\n",
    "        else:\n",
    "            wavelengths = wavelength_slices[0]\n",
    "            spaxel_loc = spaxel_locs[0]\n",
    "            vmin_vmax_vals = vmin_vmax[0]\n",
    "            if y_scale:\n",
    "                y_scales = y_scale[0]\n",
    "\n",
    "        # Loop through each wavelength slices\n",
    "        for i, wave_slice in enumerate(wavelengths):\n",
    "\n",
    "            if float(wavstart) <= wave_slice*10**-6 <= float(wavend):\n",
    "                \n",
    "                # --------------------------------------------2-D Cube Slice------------------------------------------------\n",
    "            \n",
    "                # Min & Max Image Values & Scaling\n",
    "                if len(vmin_vmax_vals) != 1:\n",
    "                    vmax_val = vmin_vmax_vals[i][1]\n",
    "                    vmin_val = vmin_vmax_vals[i][0]\n",
    "                else:\n",
    "                    vmax_val = vmin_vmax_vals[0][1]\n",
    "                    vmin_val = vmin_vmax_vals[0][0]\n",
    "\n",
    "                slicewave = wave_slice\n",
    "                nslice = int((slicewave - crval3)/cdelt3) # The slice of the cube we want to plot\n",
    "                ax1 = plt.subplot(gs[0+plot_count], projection=wcs, slices=('x', 'y', nslice)) # Set up the subplot space\n",
    "                # ax1 = plt.subplot(3,len(wavelength_slices), 0+plot_count, projection=wcs, slices=('x', 'y', nslice)) # Set up the subplot space\n",
    "\n",
    "                slice_mean = np.nanmean(cube[(nslice-2):(nslice+2), :, :], axis=0) # Mean of the slice looking in the range (nslice-2):(nslice+2)\n",
    "                slice_norm = ImageNormalize(slice_mean, vmin=vmin_val, vmax=vmax_val, stretch=AsinhStretch()) # Normalize &stretch \n",
    "                slice_image = ax1.imshow(slice_mean, norm=slice_norm, origin='lower', aspect='auto', cmap=cmap) # Plot slice\n",
    "\n",
    "                cb_image = fig.colorbar(slice_image, fraction=0.046, pad=0.04)\n",
    "                cb_image.set_label('MJy/sr', labelpad=-1, fontsize=22)\n",
    "                cb_image.ax.tick_params(labelsize=20)\n",
    "                cb_image.ax.yaxis.get_offset_text().set_fontsize(20)\n",
    "                \n",
    "                ax1.set_xlabel('RA', fontsize=22)\n",
    "                ax1.set_ylabel('DEC', labelpad=-1, fontsize=22)\n",
    "                # ax1.grid(color='white', ls='solid')\n",
    "                ax1.set_title('Detector {} \\n Grating/Filter: {}/{} \\n {} microns'.format(s3d[0].header['DETECTOR'], s3d[0].header['GRATING'], s3d[0].header['FILTER'], str(slicewave)), fontsize=25)\n",
    "                ax1.tick_params(axis='both', which='major', labelsize=20)\n",
    "                ax1.coords[0].set_ticklabel(rotation=13, ha='right', pad=24)\n",
    "\n",
    "                # ------------------------------------------Spaxel 1-D Spectrum---------------------------------------------\n",
    "                \n",
    "                # Zoom in on a Spaxel: Spectrum\n",
    "                loc = [spaxel_loc[i][0], spaxel_loc[i][1]]\n",
    "                x1d3flux_loc = cube[:, loc[1], loc[0]]\n",
    "                # ax2 = plt.subplot(3,len(wavelength_slices), int(total_num_plots/3)+plot_count)\n",
    "                ax2 = plt.subplot(gs[int(total_num_plots/3)+plot_count])\n",
    "\n",
    "                # Spaxel Box Highlight \n",
    "                spaxel_rect = plt.Rectangle((loc[0]-.5, loc[1]-.5), 1, 1, fill=False, color='black', linewidth=2)\n",
    "                ax1.add_patch(spaxel_rect)\n",
    "                \n",
    "                ax2.plot(x1d3wave, x1d3flux_loc, linewidth=1, color=colors[i])\n",
    "                ax2.grid(linewidth=2)\n",
    "                ax2.set_xlabel('$\\u03BB [\\u03BC$m]', fontsize=22)\n",
    "                ax2.set_ylabel(\"Surface Brightness \\n (MJy/sr)\", fontsize=22)\n",
    "                ax2.set_title('Spaxel at (x, y)='+repr(loc), fontsize=25)\n",
    "                ax2.tick_params(axis='both', which='major', labelsize=20)\n",
    "                ax2.yaxis.get_offset_text().set_fontsize(15)\n",
    "                \n",
    "                # Scale Information\n",
    "                if y_scale:\n",
    "                    ymin, ymax = y_scales[i][0], y_scales[i][1]\n",
    "                else:\n",
    "                    ymin, ymax = ax2.set_ylim()\n",
    "                \n",
    "                ax2.set_ylim(ymin, ymax)\n",
    "                ax2.xaxis.set_tick_params(labelsize=20)\n",
    "                ax2.yaxis.set_tick_params(labelsize=20)\n",
    "                ax2.set_aspect(0.5/ax2.get_data_ratio())\n",
    "                \n",
    "                # -----------------------------------------------Weight Map-------------------------------------------------\n",
    "                \n",
    "                # Corresponding Weight Map (wmap) for Cube Slice\n",
    "                ax3 = plt.subplot(gs[int(total_num_plots)-np.array(wavelength_slices).size+plot_count], projection=wcs, slices=('x', 'y', nslice)) # Set up the subplot space\n",
    "                # ax3 = plt.subplot(3, len(wavelength_slices), int(total_num_plots)-len(wavelength_slices)+plot_count, projection=wcs, slices=('x', 'y', nslice)) # Set up the subplot space\n",
    "                \n",
    "                slice_mean_wmap = np.nanmean(wmap[(nslice-2):(nslice+2), :, :], axis=0) # Mean of the wmap slice looking in the range (nslice-2):(nslice+2)\n",
    "                slice_norm_wmap = ImageNormalize(slice_mean_wmap, stretch=AsinhStretch()) # Normalize & stretch\n",
    "                slice_wmap = ax3.imshow(slice_mean_wmap, norm=slice_norm_wmap, origin='lower', aspect='auto', cmap=cmap) # Plot slice\n",
    "\n",
    "                cb_wmap = fig.colorbar(slice_wmap, fraction=0.046, pad=0.04)\n",
    "                cb_wmap.set_label('Weight', labelpad=-1, fontsize=22)\n",
    "                cb_wmap.ax.tick_params(labelsize=20)\n",
    "                cb_wmap.ax.yaxis.get_offset_text().set_fontsize(20)\n",
    "                \n",
    "                ax3.set_xlabel('RA', fontsize=22)\n",
    "                ax3.set_ylabel('DEC', labelpad=-1, fontsize=22)\n",
    "                # ax3.grid(color='gray', ls='solid')\n",
    "                ax3.set_title(str(slicewave)+' microns: Weight Map', fontsize=25)\n",
    "                ax3.tick_params(axis='both', which='major', labelsize=20)\n",
    "                ax3.coords[0].set_ticklabel(rotation=13, ha='right', pad=24)\n",
    "\n",
    "                plot_count += 1\n",
    "                    \n",
    "            else:\n",
    "                None\n",
    "    \n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=title_font)\n",
    "        plt.subplots_adjust(top=0.8) \n",
    "    \n",
    "    fig.tight_layout(rect=[0, 0, 0.98, 0.98])\n",
    "\n",
    "    if save_figure:\n",
    "        fig.savefig(root+\".png\", dpi=24, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb2cd6b-7396-4d7f-8954-49654f34a598",
   "metadata": {},
   "source": [
    "## 4. Directory Set-Up <a id='dir_setup'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36acc0ff-0a60-4f60-abad-bd71e686c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To rerun the notebook and all the pipeline steps set runflag=True\n",
    "runflag = True \n",
    "\n",
    "# Demo directory -- contains pre-computed products\n",
    "if not runflag:\n",
    "    output_dir = './nirspec_ifu_02732_demo/'\n",
    "\n",
    "# Rerun directory\n",
    "elif runflag:\n",
    "    # If you want to actually re-download the data and run everything offline, \n",
    "    # then comment out this line, set runflag=True, & specify a desired local directory\n",
    "    output_dir = './nirspec_ifu_02732_rerun/'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b01c250-2f66-4de7-ba7b-fdbcbd7a99af",
   "metadata": {},
   "source": [
    "## 5. Download the Data <a id='data'></a>\n",
    "\n",
    "<hr style=\"border:1px solid gray\">\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Tip:</b> To download the data from MAST, you must input your MAST authorization token. Get your MAST Token Here: https://auth.mast.stsci.edu/token. Additionally, be sure to follow [astroquery installation procedures](https://astroquery.readthedocs.io/en/latest/index.html#) to properly run this cell. \n",
    "    \n",
    "</div> \n",
    "\n",
    "| Target: NGC 7319 AGN |       |   |   |   |\n",
    "|:-----------:|:-------:|---|---|---|\n",
    "| Proposal ID | 02732 |   |   |   |\n",
    "| [GRATING/FILTER](https://jwst-docs.stsci.edu/jwst-near-infrared-spectrograph/nirspec-observing-modes/nirspec-ifu-spectroscopy)   | PRISM/CLEAR | λ: 0.6–5.3 μm (a low resolution, R ~ 100) |   |   |\n",
    "|   DURATION  | 160.478 [s] | Total duration of one exposure |   |   |   |\n",
    "|   READPATT  | NRSIRS2RAPID | Readout Pattern |   |   |   |\n",
    "|   PATTTYPE  | CYCLING | Primary dither pattern type |   |   |\n",
    "|   PATTSIZE  | LARGE | Primary dither pattern size (1.0\" extent) |   |   |\n",
    "|   NUMDTHPT  | 8 | Total number of points in pattern |   |   | \n",
    "|   SRCTYAPT  | UNKNOWN | Source Type selected in APT |   |   | \n",
    "\n",
    "> **Note:** The presence of a physical gap between detectors affects high-resolution IFU observations because the spectra are long enough to span both NIRSpec detectors. When using the grating-filter combination G140H/F070LP (or PRISM/CLEAR) the resulting spectra do not have any gaps because the spectra do not extend beyond NRS1. [More Info ...](https://jwst-docs.stsci.edu/jwst-near-infrared-spectrograph/nirspec-operations/nirspec-ifu-operations/nirspec-ifu-wavelength-ranges-and-gaps#NIRSpecIFUWavelengthRangesandGaps-Wavelengthgaps)\n",
    "\n",
    "The cell below downloads the raw uncalibrated data along with the stage 2 and stage 3 products that are available in MAST. MAST products will get saved to a folder called `mast_products` within the designated output directory defined earlier in this notebook. These files have already been pre-downloaded and stored in a provided demo directory. To get the most up-to-date products set `runflag = True` and rerun this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f205522d-f3ca-4053-9040-7f43f0cd62fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download data from MAST \n",
    "\n",
    "# Setup your account \n",
    "\n",
    "# NOTE:\n",
    "# The data in this notebook is public and does not require a token.\n",
    "# For other data sets, uncomment the following line and enter your\n",
    "# token at the prompt.\n",
    "\n",
    "# Observations.login(token=None)\n",
    "\n",
    "sessioninfo = Observations.session_info()\n",
    "\n",
    "# Define the general search criteria\n",
    "obs = Observations.query_criteria(\n",
    "        obs_collection='JWST',\n",
    "        instrument_name=['NIRSPEC/IFU'],\n",
    "        proposal_id='02732')\n",
    "\n",
    "# Print the Observations returned from the general search criteria\n",
    "products = Observations.get_product_list(obs)\n",
    "# print(products)\n",
    "\n",
    "# Filter the list of observations\n",
    "# In this case we look for UNCAL products and ASN files to manually run pipeline stage 1-3\n",
    "# We look for pre-processed MAST products for comparison: RATE (stage 1) & CAL (stage 2&3) & S3D (stage 2&3) & X1D (stage2&3)  \n",
    "filtered = Observations.filter_products(products,\n",
    "                                        productSubGroupDescription=[\"UNCAL\", \"ASN\"],\n",
    "                                        mrp_only=False)\n",
    "# Print the filtered products\n",
    "number = len(filtered)\n",
    "for k in range(number):\n",
    "    print(filtered['productFilename'][k])\n",
    "\n",
    "# Download the filtered products\n",
    "# This creates a mastDownload directory, unless you set flat=True and set a download_dir\n",
    "for i in range(len(filtered)):\n",
    "    mast_products_dir = output_dir+'mast_products/'\n",
    "    if not os.path.exists(mast_products_dir):\n",
    "        os.makedirs(mast_products_dir)\n",
    "    if runflag:\n",
    "        Observations.download_products(filtered[i], mrp_only=False, cache=False, flat=True, download_dir=mast_products_dir) # Override any cached files and download the most up-to-date ones\n",
    "    else:\n",
    "        Observations.download_products(filtered[i], mrp_only=False, cache=True, flat=True, download_dir=mast_products_dir) # Find any cached files first before downloading new ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d692537-b0fa-4221-8f0f-23816e51097d",
   "metadata": {},
   "source": [
    "### 6. Stage 1 <a id='stage1'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684360fc-e0d4-4a1c-be06-8d7effe5a6da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stage 1 Processing \n",
    "\n",
    "if runflag:\n",
    "\n",
    "    for uncal_file in sorted(glob.glob(mast_products_dir+'*nrs1_uncal.fits')): \n",
    "\n",
    "        print(\"Applying Stage 1 Corrections & Calibrations to: \" + os.path.basename(uncal_file))\n",
    "\n",
    "        result = Detector1Pipeline.call(uncal_file,\n",
    "                                        save_results=True,\n",
    "                                        output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00294b2-4eec-4178-bdae-313e20bb8045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stage 1 slope products -- level 2a images\n",
    "\n",
    "# Plot 4th (out of 8) dither position (NRS1 & NRS2) for GRATING/FILTER G140H/F100LP combination  \n",
    "for rate_file in sorted(glob.glob(output_dir+'*00004_nrs?_rate.fits')):\n",
    "    \n",
    "    ratefile_open = datamodels.open(rate_file)\n",
    "    ratefile_sci = ratefile_open.data # Get the pixel data (the SCI extension of the fits file)\n",
    "    ratefile_dq = ratefile_open.dq # The Data Quality Map Data\n",
    "    \n",
    "    show_image(ratefile_sci, 0, 10, units='DN/s', zoom_in=[500, 550, 1250, 1300],\n",
    "               title='Countrate Image \\n Detector: {} \\n 8-Cycle Dither Position Index: {} \\n GRATING/FILTER: {}/{}'.format(ratefile_open.meta.instrument.detector,\n",
    "                                                                                                                            ratefile_open.meta.dither.position_number, \n",
    "                                                                                                                            ratefile_open.meta.instrument.grating,\n",
    "                                                                                                                            ratefile_open.meta.instrument.filter)) # rate files have units of DN/s\n",
    "    show_image(ratefile_dq, 0, 10, units='Bit Value', scale='linear', zoom_in=[500, 550, 1250, 1300],\n",
    "               title='Data Quality Map \\n Detector: {} \\n 8-Cycle Dither Position Index: {} \\n GRATING/FILTER: {}/{}'.format(ratefile_open.meta.instrument.detector,\n",
    "                                                                                                                             ratefile_open.meta.dither.position_number, \n",
    "                                                                                                                             ratefile_open.meta.instrument.grating,\n",
    "                                                                                                                             ratefile_open.meta.instrument.filter)) # rate files have units of DN/s      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9c863d-3864-439f-bf04-281ea5389a9a",
   "metadata": {},
   "source": [
    "### 7. Stage 2  <a id='stage2'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "This IFU data set focuses on an AGN target, which has a compact region at the center of its galaxy that can be considered a point source. To treat this IFU data as a point source, one must change the `SRCTYPE=POINT` header keyword in the `cal.fits` files before running stages 2 and 3 of the calibration pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe6882-2880-4172-b65e-e6e83383dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating the IFU data as a point source \n",
    "# To run as a point source, alter the rate file header keywrod SRCTYAPT=POINT & rerun stage 2 of the pipeline \n",
    "# Loop through the copied rate files and update the source type keyword\n",
    "for rate_file in sorted(glob.glob(output_dir+'*nrs1_rate.fits')):\n",
    "    rate_file_hdu = fits.open(rate_file, 'update')\n",
    "    \n",
    "    # Change source type to point \n",
    "    rate_file_hdu[0].header['SRCTYAPT'] = 'POINT'\n",
    "    \n",
    "    rate_file_hdu.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22b08e2-dbde-4053-83b4-8195fd452684",
   "metadata": {},
   "source": [
    "During stage 2 of the pipeline, the countrate (slope) image products from stage 1, which have units of DN/s, are converted to units of surface brightness (MJy/sr) for both extended and point sources (as of DMS build 9.3/CAL_VER 1.10.2). For IFU point sources, the `extract_1d` step is controlled by a different set of parameters in the EXTRACT1D reference file: \n",
    "\n",
    "> For a point source, the spectrum is extracted using circular aperture photometry, **optionally (automatically) including background subtraction** using a circular annulus. [More Info ...](https://jwst-pipeline.readthedocs.io/en/latest/jwst/extract_1d/description.html)\n",
    "\n",
    "When processing the IFU as a point source, the `extract_1d` step will automatically apply background subtraction unless otherwise told not to. The `extract_1d` step will also use the default circular extraction apertures for the source and background, an example of how to modify the EXTRACT1D reference file can be found at the end of this notebook.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> Note there has been a bug in the `cube_build` step that caused the point source flux to not be conserved when using different spatial sampling. A fix has been implemented as of release DMS build 9.3/CAL_VER 1.10.2. In order to enable the correct functionality, the units of the cal.fits files and cubes will now be in surface brightness, and only the 1-D extracted spectra will be in units of Jy.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a85ff57-18ea-4a81-87c3-7d3f0aff5082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stage 2 Processing \n",
    "\n",
    "if runflag:\n",
    "    \n",
    "    # Process each rate file separately \n",
    "    for rate_file in sorted(glob.glob(output_dir+'*nrs1*rate.fits')):\n",
    "            \n",
    "        print(\"Applying Stage 2 Calibrations & Corrections to: \" + os.path.basename(rate_file))\n",
    "\n",
    "        result = Spec2Pipeline.call(rate_file,\n",
    "                                    save_results=True,\n",
    "                                    output_dir=output_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bafbb3-5646-4405-94b7-179523220ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2 Products -- Calibrated 3-D data cube for PRISM/CLEAR (only falls on NRS1)\n",
    "\n",
    "# Plotting the 4th (out of 8) dither position\n",
    "stage2_s3d_file = sorted(glob.glob(output_dir+'*00004_nrs1_s3d.fits')) \n",
    "\n",
    "title_stage2_rerun = 'NGC 7319 AGN \\n Level 2 IFU Product: 3-D Cube Slices vs. Corresponding 3-D Weighted Map'\n",
    "\n",
    "\n",
    "# Characteristics of the plot \n",
    "nrs1_wavelengths = [1.4, 3.3, 4.5] # Wavelength slices (microns) to take from the 3-D data cube\n",
    "nrs1_spaxel_locs = [[30, 29], [28, 39], [14, 25]] # Spaxel locations for associated 1-D spectrum (one spaxel plotted per slice)\n",
    "\n",
    "# Plot using the convience function defined above\n",
    "show_ifu_cubeslices(stage2_s3d_file, wavelength_slices=[nrs1_wavelengths], spaxel_locs=[nrs1_spaxel_locs], title=title_stage2_rerun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7e8b81-643f-4e3a-a39b-a9473b951646",
   "metadata": {},
   "source": [
    "### 8. Stage 3  <a id='stage3'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "***Level 3 ASN File***\n",
    "\n",
    "> Observations that use a nod-type/dither patterns, their exposures are related. [Association files (ASN)](https://jwst-pipeline.readthedocs.io/en/stable/jwst/associations/overview.html) describe how multiple exposures are related to one another and how they depend on one another. Processing an ASN file permits exposures to be calibrated, archived, retrieved, and reprocessed as a set rather than individual objects. IFU exposures taken with a dither pattern are not used for pixel-to-pixel background subtraction by the calibration pipeline (unlike exposures taken with a nod pattern).\n",
    "\n",
    "Therefore, all calibration files (`cal.fits`) in our spec3 ASN file should be labeled as science exposures (`exptype: science`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7220fadc-73c6-4d3d-b03f-cfc71865c496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Copy ASN file from MAST into the stage 1 rerun directory\n",
    "\n",
    "asnfile_mast = glob.glob(mast_products_dir+'*_spec3_00001_asn.json')[0] # ASN file found in MAST\n",
    "\n",
    "asnfile_rerun_point = output_dir + os.path.basename(asnfile_mast) # New ASN file path\n",
    "if not os.path.exists(asnfile_rerun_point):\n",
    "    copy(asnfile_mast, asnfile_rerun_point)\n",
    "    \n",
    "# Check the ASN file contents\n",
    "with open(asnfile_rerun_point, 'r') as f_obj:\n",
    "    asnfile_rerun_point_data = json.load(f_obj)\n",
    "        \n",
    "asnfile_rerun_point_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8384e3a3-972e-4473-baf4-7c34544dd845",
   "metadata": {},
   "source": [
    "#### 8.1 New Outlier Detection Algorithm<a id='outlier_detection_new'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "The new outlier detection algorithm for IFU data (as of DMS build B9.3rc1/CAL_VER 1.11.0) implements the basic outlier detection algorithm -- searches for pixels that are consistent outliers in the calibrated images created by the `calwebb_spec2` pipeline. The algorithm generally operates as follows:\n",
    "\n",
    "> * Identifies outlier pixels by comparing them with their neighboring pixels in the spatial direction across a set of input files within an association.\n",
    "> * For NIRSpec data, it calculates differences between pixels located above and below each science pixel.\n",
    "> * The pixel differences for every input model in the association are computed and stored in a stack of pixel differences.\n",
    "> * For each pixel, the algorithm determines the minimum difference across this stack and then performs normalization. This normalization process employs a local median derived from the difference array, with the size of the median determined by the kernel size.\n",
    "> * A pixel is flagged as an outlier if this normalized minimum difference is greater than the input threshold percentage. \n",
    "> * Pixels that are found to be outliers are flaged in in the DQ array.\n",
    "> * [More Info ...](https://jwst-pipeline.readthedocs.io/en/latest/jwst/outlier_detection/outlier_detection_ifu.html#outlier-detection-ifu)\n",
    "\n",
    "**[The outlier_detection step for IFU data has the following optional arguments that control the behavior of the processing](https://github.com/spacetelescope/jwst/blob/master/docs/jwst/outlier_detection/arguments.rst):**\n",
    "\n",
    "* `kernel_size` (string, default='7'): The size of the kernel to use to normalize the pixel differences. The kernel size must only contain odd values.\n",
    "* `threshold_percent` (float, default=99.8): The threshold (in percent) of the normalized minimum pixel difference used to identify bad pixels. Pixels with a normalized minimum pixel difference above this percentage are flagged as a outlier.\n",
    "* `save_intermediate_results` (boolean, default=False): Specifies whether or not to save any intermediate products created during step processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a09918-9e92-4f5b-954f-a0de70aa56d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun stage 3 with outlier detection on\n",
    "if runflag:\n",
    "    result = Spec3Pipeline.call(asnfile_rerun_point,\n",
    "                                save_results=True,\n",
    "                                output_dir=output_dir,\n",
    "                                steps={\"outlier_detection\": {\"skip\": False,\n",
    "                                                             \"save_results\": True,\n",
    "                                                             \"kernel_size\": '3 3'},\n",
    "                                                             \"extract_1d\": {\"subtract_background\": False}}) # Do not automatically apply background subtraction until we modify the extraction region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c596da-927d-41a1-93c3-4731bed51ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3 Products -- Combined Calibrated 3-D data cube for PRISM/CLEAR \n",
    "\n",
    "stage3_s3d_file_point = sorted(glob.glob(output_dir+'*nirspec_prism-clear_s3d.fits')) \n",
    "\n",
    "title_stage3_rerun_point = 'NGC 7319 AGN \\n Level 3 IFU Product: 3-D Cube Slices vs. Corresponding 3-D Weighted Map'\n",
    "\n",
    "# Characteristics of the plot \n",
    "nrs1_wavelengths = [1.4, 3.3, 4.5] # Wavelength slices (microns) to take from the 3-D data cube\n",
    "nrs1_spaxel_locs = [[30, 29], [28, 39], [14, 25]] # Spaxel locations for associated 1-D spectrum (one spaxel plotted per slice)\n",
    "vmin_vmax_point = [[0, 150], [0, 150], [0, 150]]\n",
    "\n",
    "# Plot using the convience function defined above\n",
    "show_ifu_cubeslices(stage3_s3d_file_point, wavelength_slices=[nrs1_wavelengths], spaxel_locs=[nrs1_spaxel_locs], vmin_vmax=[vmin_vmax_point], title=title_stage3_rerun_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff7886-30b8-42a6-bf72-a5eb04fe19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3 Products -- Extracted 1-D Spectrum \n",
    "\n",
    "# Combined 1-D extracted spectrum\n",
    "x1d3_rerun_point = datamodels.open(glob.glob(output_dir+'*nirspec_prism-clear_x1d.fits')[0])\n",
    "\n",
    "# Wavelength & Surface Brightness Arrays\n",
    "x1d3wave_rerun_point = x1d3_rerun_point.spec[0].spec_table.WAVELENGTH\n",
    "x1d3flux_rerun_point = x1d3_rerun_point.spec[0].spec_table.FLUX\n",
    "\n",
    "# Plot the Extracted 1-D Spectrum\n",
    "fig = plt.figure(figsize=(15, 9))\n",
    "\n",
    "plt.plot(x1d3wave_rerun_point, x1d3flux_rerun_point, linewidth=2)\n",
    "\n",
    "# Where wavelength slice was taken above\n",
    "plt.vlines(1.4, 0., 400., 'black', 'dotted', label='1.4 microns')\n",
    "plt.vlines(3.3, 0., 400., 'red', 'dotted', label='3.3 microns')\n",
    "plt.vlines(4.5, 0., 400., 'green', 'dotted', label='4.5 microns')\n",
    "\n",
    "plt.xlabel(r'$\\lambda [\\mu$m]', fontsize=20)\n",
    "plt.ylabel('Flux (Jy)', fontsize=20)\n",
    "plt.title(\"NGC 7319 AGN \\n Level 3 IFU Product in MAST: Extracted 1-D Spectrum\", fontsize=20)\n",
    "plt.ylim(0, 10**-1.6)\n",
    "plt.ticklabel_format(axis='y', style='sci', scilimits=(0, -2))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d98027-3ea6-415f-b5d4-8fe7397445a2",
   "metadata": {},
   "source": [
    "#### 8.2 Extract 1-D Step: Modified Reference File<a id='extract_1d'></a>\n",
    "<hr style=\"border:1px solid gray\">  \n",
    "\n",
    "As a point source, the `extract_1d` step is controlled by a different set of parameters in the EXTRACT1D reference file:\n",
    "\n",
    ">[Extraction for 3-D IFU Data:](https://jwst-pipeline.readthedocs.io/en/latest/jwst/extract_1d/description.html)\n",
    ">\n",
    "> For point source data the extraction aperture is centered at the RA/DEC target location indicated by the header. If the target location is undefined in the header, then the extraction region is the center of the IFU cube.\n",
    ">\n",
    ">For point sources a circular extraction aperture is used, along with an optional circular annulus for background extraction and subtraction. The size of the extraction region and the background annulus size varies with wavelength. The extraction related vectors are found in the asdf EXTRACT1D reference file. For each element in the wavelength vector there are three size components: `radius`, `inner_bkg`, and `outer_bkg`. The radius vector sets the extraction size; while `inner_bkg` and `outer_bkg` specify the limits of an annular background aperture. \n",
    "\n",
    "Here, we show how to modify the EXTRACT1D reference file to obtain better results. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> The default extraction aperture radius has been set to match what was used to derive the flux calibration. If you want to use a different aperture size, you will need to compute and apply a custom aperture correction to ensure the correct flux, as we have not yet updated the aperture correction reference files.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8284ef00-acf5-49e7-8f8d-e3cf6efd7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction Region Preview\n",
    "# Open Combined 3-D Cube FITS file\n",
    "s3d = fits.open(glob.glob(output_dir+'*nirspec_prism-clear_s3d.fits')[0])\n",
    "cube = s3d[1].data  # Science data\n",
    "\n",
    "# Plot the full IFU cube\n",
    "ax = plt.subplot(1, 1, 1)  #, projection=wcs, slices=('x', 'y', nslice3)) # Set up the subplot space\n",
    "slice_mean = np.nanmean(cube[400:500, :, :], axis=0) # Mean of the slice looking in the range (nslice2-2):(nslice2+2)\n",
    "slice_norm = ImageNormalize(slice_mean, vmin=0, vmax=150, stretch=AsinhStretch()) # Normalize &stretch\n",
    "slice_full = ax.imshow(slice_mean, norm=slice_norm, origin='lower', cmap='jet') # Plot slice\n",
    "\n",
    "# Colorbar\n",
    "cb_image = plt.colorbar(slice_full, fraction=0.046, pad=0.04)\n",
    "cb_image.set_label('MJy/sr', labelpad=-1, fontsize=10)\n",
    "cb_image.ax.tick_params(labelsize=10)\n",
    "cb_image.ax.yaxis.get_offset_text().set_fontsize(10)\n",
    "\n",
    "radius = Circle((29, 29), 9, fill=False, label='Radius')\n",
    "inner_bkg = Circle((29, 29), 10, color='b', fill=False, label='Inner Background Radius')\n",
    "outer_bkg = Circle((29, 29), 15, color='r', fill=False, label='Outer Background Radius')\n",
    "ax.add_patch(radius)\n",
    "ax.add_patch(inner_bkg)\n",
    "ax.add_patch(outer_bkg)\n",
    "ax.legend(fontsize=10)\n",
    "ax.set_xlabel('X (pixels)', fontsize=10)\n",
    "ax.set_ylabel('Y (pixels)', fontsize=10)\n",
    "ax.grid(color='white', ls='solid')\n",
    "ax.set_title('Full IFU Cube: \\n Extraction Region Preview', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcbfef1-86f4-47f3-ac6a-c3ac7cf2af76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab the default extract1d reference file and copy to working directory\n",
    "extract1d_ref_og = Spec3Pipeline().get_reference_file(glob.glob(output_dir+'*nirspec_prism-clear_s3d.fits')[0], 'extract1d')\n",
    "if not os.path.exists(output_dir+os.path.basename(extract1d_ref_og)):\n",
    "    copy(extract1d_ref_og, output_dir+os.path.basename(extract1d_ref_og))\n",
    "\n",
    "if runflag:\n",
    "    # Make Changes to the ASDF file and Write to a new file\n",
    "    with asdf.open(output_dir+os.path.basename(extract1d_ref_og), mode='rw') as ff:\n",
    "        ff.tree['data']['radius'] = np.full((2048,), 9, dtype='float32')\n",
    "        ff.tree['data']['inner_bkg'] = np.full((2048,), 10, dtype='float32')\n",
    "        ff.tree['data']['outer_bkg'] = np.full((2048,), 15, dtype='float32')\n",
    "        ff.write_to(output_dir+'new_extract1d_reference_file.asdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab34faf-b2f2-469a-ad8c-8920f9e01786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun only the extract1d step with the new/modified reference file with background subtraction on\n",
    "\n",
    "if runflag:\n",
    "    Extract1dStep.call(glob.glob(output_dir+'*nirspec_prism-clear_s3d.fits')[0], \n",
    "                       save_results=True,\n",
    "                       output_dir=output_dir, \n",
    "                       override_extract1d=output_dir+'new_extract1d_reference_file.asdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e10a9e2-1040-4836-b50e-903413d7defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display new 1-D spectrum\n",
    "\n",
    "# Combined 1D extracted spectrum\n",
    "x1d3 = datamodels.open(glob.glob(output_dir+'*nirspec_prism-clear_extract1dstep.fits')[0])\n",
    "\n",
    "# Wavelength & Surface Brightness Arrays\n",
    "x1d3wave = x1d3.spec[0].spec_table.WAVELENGTH\n",
    "x1d3flux = x1d3.spec[0].spec_table.FLUX\n",
    "\n",
    "# Plot the Extracted 1D Spectrum\n",
    "fig = plt.figure(figsize=(15, 9))\n",
    "\n",
    "plt.plot(x1d3wave, x1d3flux, linewidth=2)\n",
    "\n",
    "# Where wavelength slice was taken above\n",
    "plt.vlines(1.4, 0., 400., 'black', 'dotted', label='1.4 microns')\n",
    "plt.vlines(3.3, 0., 400., 'red', 'dotted', label='3.3 microns')\n",
    "plt.vlines(4.5, 0., 400., 'green', 'dotted', label='4.5 microns')\n",
    "\n",
    "plt.xlabel(r'$\\lambda [\\mu$m]')\n",
    "plt.ylabel('Flux (Jy)', fontsize=20)\n",
    "plt.title(\"NGC 7319 AGN \\n Level 3 IFU Product: Extracted 1-D Spectrum with Background Subtraction\")\n",
    "plt.ylim(0, 10**-1.6)\n",
    "plt.ticklabel_format(axis='y', style='sci', scilimits=(0, -2))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b450acc1-9f3d-4d57-a710-2c09d0518aef",
   "metadata": {},
   "source": [
    "## About This Notebook <a id='about'></a>\n",
    "<hr style=\"border:1px solid gray\">  \n",
    "\n",
    "**Authors**: Kayli Glidic (kglidic@stsci.edu), Leonardo Ubeda (lubeda@stsci.edu)\n",
    "\n",
    "**Update On**: 2023-08-11"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
